{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook Goals\n",
    "The goal of this notebook is to compare the outcomes of FHA and HOLC zones on home value, ownership, and segregation.  \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context('paper')\n",
    "\n",
    "paper_cmap = {\"A\":\"#5FCE72\",\"B\":\"#0BC0ED\",\"C\":\"#FFD419\",\"D\":\"#FF4B19\"}\n",
    "paper_colors = LinearSegmentedColormap('paper_colors', paper_cmap)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import glob\n",
    "import requests\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely import wkt\n",
    "\n",
    "import psycopg2  # (if it is postgres/postgis)\n",
    "conn = psycopg2.connect(database=\"postgres\", user=\"wonyoungso\", password=\"\",\n",
    "    host=\"localhost\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://wonyoungso:@localhost:5432/postgres')\n",
    "\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from patsylearn import PatsyModel, PatsyTransformer\n",
    "\n",
    "import libpysal as ps\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as st\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Get Data\n",
    "### 0.1 Get data from HOLC cities\n",
    "\n",
    "`chicago_historical` is the baseline dataset I'm working with which has the cross-walked census boundaries. The normalized data has been normalized by year, so they represent the number of standard deviations from the norm for that particulalr year. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_final = gpd.read_file('data/chicago_census_historical/chicago_census_historical.shp')\n",
    "\n",
    "df_final = df_final.rename(columns={'asian': 'asian',\n",
    " 'asian_pe_1': 'asian_perc_norm',\n",
    " 'asian_perc': 'asian_perc',\n",
    " 'black': 'black',\n",
    " 'black_norm': 'black_norm',\n",
    " 'black_pe_1': 'black_perc_norm',\n",
    " 'black_perc': 'black_perc',\n",
    " 'college': 'college',\n",
    " 'college__1': 'college_perc_norm',\n",
    " 'college_pe': 'college_perc',\n",
    " 'gisjoin': 'gisjoin',\n",
    " 'gisjoin_19': 'gisjoin_1940',\n",
    " 'hispanic': 'hispanic',\n",
    " 'hispanic_1': 'hispanic_perc_norm',\n",
    " 'hispanic_p': 'hispanic_perc',\n",
    " 'holc_grade': 'holc_grade',\n",
    " 'homes': 'homes',\n",
    " 'ln_homeval': 'ln_homeval_norm',\n",
    " 'ln_income_': 'ln_income_norm',\n",
    " 'ln_media_1': 'ln_median_homevalue_adj',\n",
    " 'ln_median_': 'ln_median_income',\n",
    " 'map_id': 'map_id',\n",
    " 'median_h_1': 'median_homevalue_adj',\n",
    " 'median_hom': 'median_homevalue',\n",
    " 'median_i_1': 'median_income',\n",
    " 'median_inc': 'median_income_adj',\n",
    " 'other': 'other',\n",
    " 'other_perc': 'other_perc',\n",
    " 'owned_pe_1': 'owned_perc_norm',\n",
    " 'owned_perc': 'owned_perc',\n",
    " 'populati_1': 'population_density',\n",
    " 'populati_2': 'population_density_norm',\n",
    " 'populati_3': 'population_norm',\n",
    " 'population': 'population',\n",
    " 'unemploy_1': 'unemployed_perc',\n",
    " 'unemploy_2': 'unemployed_perc_norm',\n",
    " 'unemployed': 'unemployed',\n",
    " 'white': 'white',\n",
    " 'white_norm': 'white_norm',\n",
    " 'white_pe_1': 'white_perc_norm',\n",
    " 'white_perc': 'white_perc',\n",
    " 'year': 'year'})\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.2 Feature creation\n",
    "Need to create some extra features, including for later propensity scoring to find similarity between 'before' tracts. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_final['nonblack_perc'] = 1-df_final['black_perc']/df_final['population']\n",
    "\n",
    "df_final['perc_college_10plus'] = [1 if x>0.10  else 0 for x in df_final['college_perc']]\n",
    "\n",
    "\n",
    "# Need to create some extra features for the propensity scoring to increase similarity between 'before' tracts. \n",
    "df_final['perc_black_20plus'] = [1 if x>0.20  else 0 for x in df_final['black_perc']]\n",
    "df_final['perc_college_10plus'] = [1 if x>0.10  else 0 for x in df_final['college_perc']]\n",
    "\n",
    "# Create a point that represents roughly downtown is \n",
    "downtown = Point(-87.62,41.855)\n",
    "df_final['dist_downtown'] = df_final.distance(Point(-87.62,41.855))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create different treatment periods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_final1 = df_final[df_final.year!=1950]\n",
    "df_final1.loc[df_final1.year<=1940,'period']='pre'\n",
    "df_final1.loc[(df_final1.year>1940)&\n",
    "                   (df_final1.year<=1980),'period']='post'\n",
    "\n",
    "df_final1.loc[(df_final1.year>1980),'period']='reversal'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.3 Feature creation for Propensity Score Matching\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Create the D vs non-D FHA labels\n",
    "df_final1['D_fha'] = df_final1.apply(lambda x: 'D' if x['fha_grade']=='D' else 'not_D_fha',axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.4 Clean and standardize "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def decade_scaler(x):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    return scaler.fit_transform(x)\n",
    "\n",
    "def stand_data(df,features,groups = ['map_id','year']):\n",
    "    for f in features: \n",
    "        df['{}_norm'.format(f)] = df[groups+features].groupby(groups).transform(lambda x: (x-x.mean())/x.std())[f]\n",
    "    \n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def clean_tracts(df):\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    df = df[(df['ln_median_homevalue_adj']>0)&(df['owned_perc']>0)]\n",
    "    df=df.drop_duplicates(['gisjoin','year'])\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_final1=clean_tracts(df_final1)\n",
    "\n",
    "## Already did this earlier\n",
    "# stand_features=['owned_perc','ln_median_homevalue_adj','white_perc','black_perc','unemployed_perc','asian_perc','hispanic_perc',\n",
    "#                'population_density','population','ppl_per_home','dist_downtown']\n",
    "# df_final = stand_data(df_final,stand_features)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Create Entropy and Information Theory Scores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def total_E(df,feature='black_prop'):\n",
    "    tot = df['population'].sum()\n",
    "    p=(df[feature]*df['population'])/tot+.00000001\n",
    "    p = p.sum()\n",
    "    E = -p*np.log2(p)-\\\n",
    "         (1-p)*np.log2(1-p)\n",
    "        \n",
    "    return E"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def get_entropy(d): \n",
    "    \n",
    "    '''\n",
    "    Creates both the dissimiliarity measure and weighted entropy measure based on black \n",
    "    and non-black populations \n",
    "    '''\n",
    "    \n",
    "    d['e'] = 0\n",
    "    d['e_w'] = 0\n",
    "   \n",
    "    for y in d['year'].unique():\n",
    "        W = ps.weights.Queen.from_dataframe(d[d.year==y],geom_col='geometry',idVariable='gisjoin')\n",
    "        \n",
    "        #### Make sure the denominator is not zero\n",
    "        d.loc[d['year']==y,'e'] =\\\n",
    "        d.groupby('year').apply(lambda x: -x['black_perc'].values * np.log2(x['black_perc'].values + .000001)-\\\n",
    "                                           x['nonblack_perc'].values * np.log2(x['nonblack_perc'].values + .000001))[y]\n",
    "        W.transform = 'R'\n",
    "        \n",
    "        d_yr = d[d.year == y]\n",
    "        for gisjoin in d_yr['gisjoin'].values:\n",
    "\n",
    "\n",
    "            w_black_prop = np.average(list(d_yr[d_yr.gisjoin==gisjoin]['black_perc'].values)+\n",
    "                                      list(d_yr.loc[(d_yr.gisjoin.isin(W.neighbors[gisjoin])),'black_perc']),\n",
    "                                      weights=[1]+W.weights[gisjoin] )\n",
    "            w_nonblack_prop = np.average(list(d_yr[d_yr.gisjoin==gisjoin]['nonblack_perc'].values)+\n",
    "                                         list(d_yr.loc[(d_yr.gisjoin.isin(W.neighbors[gisjoin])),'nonblack_perc'].values),\n",
    "                                         weights=[1]+ W.weights[gisjoin])\n",
    "            try: \n",
    "                d.loc[(d['year']==y)&(d['gisjoin']==gisjoin),'e_w'] =-w_black_prop*np.log2(w_black_prop+.000001)-\\\n",
    "                                                w_nonblack_prop*np.log2(w_nonblack_prop+.000001)\n",
    "                \n",
    "            except (not W.neighbors[gisjoin]) or KeyError:\n",
    "                print(gisjoin)\n",
    "                d.loc[(d['year']==y)&(d['gisjoin']==gisjoin),'e_w'] = d.loc[(d['year']==y)&(d['gisjoin']==gisjoin),'e']\n",
    "    return d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df_final2 = get_entropy(df_final1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Prep for propensity score matching"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Create a DF for PSM purposes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df_final_psm = df_final2[df_final2.period=='pre']\n",
    "df_final_psm['fha_grade_psm'] = df_final_psm['fha_grade'].apply(lambda x: 'D' if x=='D' else 'not_D')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df_final_psm['black_perc_chng']= df_final_psm['black_perc'].diff()\n",
    "df_final_psm['white_perc_chng']= df_final_psm['white_perc'].diff()\n",
    "df_final_psm['population_density_chng_perc']= df_final_psm['population_density'].pct_change()\n",
    "df_final_psm['ln_median_homevalue_adj_chng_perc']= df_final_psm['ln_median_homevalue_adj'].diff()\n",
    "df_final_psm['owned_perc_chng']= df_final_psm['owned_perc'].diff()\n",
    "df_final_psm['population_chng_perc']= df_final_psm['population'].pct_change()\n",
    "df_final_psm['e_w_chng_perc']= df_final_psm['e_w'].pct_change()\n",
    "df_final_psm['e_chng']= df_final_psm['e_w'].diff()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2  Remove all public data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "public_data = gpd.read_file('data/chicago_housing/chicago_publichousing_historic.shp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "public_data.plot()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"248.187875pt\" version=\"1.1\" viewBox=\"0 0 153.721223 248.187875\" width=\"153.721223pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-26T20:57:56.688639</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.187875 \nL 153.721223 248.187875 \nL 153.721223 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 37.51925 224.64 \nL 146.521223 224.64 \nL 146.521223 7.2 \nL 37.51925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p789f0f79fc)\" d=\"M 68.855229 224.64 \nL 68.855229 7.2 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- −87.7 -->\n      <g style=\"fill:#262626;\" transform=\"translate(57.722541 239.238875)scale(0.088 -0.088)\">\n       <defs>\n        <path d=\"M 3381 1997 \nL 356 1997 \nL 356 2522 \nL 3381 2522 \nL 3381 1997 \nz\n\" id=\"ArialMT-2212\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 1131 2484 \nQ 781 2613 612 2850 \nQ 444 3088 444 3419 \nQ 444 3919 803 4259 \nQ 1163 4600 1759 4600 \nQ 2359 4600 2725 4251 \nQ 3091 3903 3091 3403 \nQ 3091 3084 2923 2848 \nQ 2756 2613 2416 2484 \nQ 2838 2347 3058 2040 \nQ 3278 1734 3278 1309 \nQ 3278 722 2862 322 \nQ 2447 -78 1769 -78 \nQ 1091 -78 675 323 \nQ 259 725 259 1325 \nQ 259 1772 486 2073 \nQ 713 2375 1131 2484 \nz\nM 1019 3438 \nQ 1019 3113 1228 2906 \nQ 1438 2700 1772 2700 \nQ 2097 2700 2305 2904 \nQ 2513 3109 2513 3406 \nQ 2513 3716 2298 3927 \nQ 2084 4138 1766 4138 \nQ 1444 4138 1231 3931 \nQ 1019 3725 1019 3438 \nz\nM 838 1322 \nQ 838 1081 952 856 \nQ 1066 631 1291 507 \nQ 1516 384 1775 384 \nQ 2178 384 2440 643 \nQ 2703 903 2703 1303 \nQ 2703 1709 2433 1975 \nQ 2163 2241 1756 2241 \nQ 1359 2241 1098 1978 \nQ 838 1716 838 1322 \nz\n\" id=\"ArialMT-38\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 303 3981 \nL 303 4522 \nL 3269 4522 \nL 3269 4084 \nQ 2831 3619 2401 2847 \nQ 1972 2075 1738 1259 \nQ 1569 684 1522 0 \nL 944 0 \nQ 953 541 1156 1306 \nQ 1359 2072 1739 2783 \nQ 2119 3494 2547 3981 \nL 303 3981 \nz\n\" id=\"ArialMT-37\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" id=\"ArialMT-2e\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-2212\"/>\n       <use x=\"58.398438\" xlink:href=\"#ArialMT-38\"/>\n       <use x=\"114.013672\" xlink:href=\"#ArialMT-37\"/>\n       <use x=\"169.628906\" xlink:href=\"#ArialMT-2e\"/>\n       <use x=\"197.412109\" xlink:href=\"#ArialMT-37\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#p789f0f79fc)\" d=\"M 122.148207 224.64 \nL 122.148207 7.2 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- −87.6 -->\n      <g style=\"fill:#262626;\" transform=\"translate(111.01552 239.238875)scale(0.088 -0.088)\">\n       <defs>\n        <path d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" id=\"ArialMT-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-2212\"/>\n       <use x=\"58.398438\" xlink:href=\"#ArialMT-38\"/>\n       <use x=\"114.013672\" xlink:href=\"#ArialMT-37\"/>\n       <use x=\"169.628906\" xlink:href=\"#ArialMT-2e\"/>\n       <use x=\"197.412109\" xlink:href=\"#ArialMT-36\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p789f0f79fc)\" d=\"M 37.51925 218.858607 \nL 146.521223 218.858607 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 41.65 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 222.008045)scale(0.088 -0.088)\">\n       <defs>\n        <path d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" id=\"ArialMT-34\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" id=\"ArialMT-31\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 266 1200 \nL 856 1250 \nQ 922 819 1161 601 \nQ 1400 384 1738 384 \nQ 2144 384 2425 690 \nQ 2706 997 2706 1503 \nQ 2706 1984 2436 2262 \nQ 2166 2541 1728 2541 \nQ 1456 2541 1237 2417 \nQ 1019 2294 894 2097 \nL 366 2166 \nL 809 4519 \nL 3088 4519 \nL 3088 3981 \nL 1259 3981 \nL 1013 2750 \nQ 1425 3038 1878 3038 \nQ 2478 3038 2890 2622 \nQ 3303 2206 3303 1553 \nQ 3303 931 2941 478 \nQ 2500 -78 1738 -78 \nQ 1113 -78 717 272 \nQ 322 622 266 1200 \nz\n\" id=\"ArialMT-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-34\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-31\"/>\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-36\"/>\n       <use x=\"194.628906\" xlink:href=\"#ArialMT-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#p789f0f79fc)\" d=\"M 37.51925 183.117688 \nL 146.521223 183.117688 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 41.70 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 186.267125)scale(0.088 -0.088)\">\n       <defs>\n        <path d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" id=\"ArialMT-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-34\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-31\"/>\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-37\"/>\n       <use x=\"194.628906\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p789f0f79fc)\" d=\"M 37.51925 147.376768 \nL 146.521223 147.376768 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 41.75 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 150.526206)scale(0.088 -0.088)\">\n       <use xlink:href=\"#ArialMT-34\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-31\"/>\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-37\"/>\n       <use x=\"194.628906\" xlink:href=\"#ArialMT-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#p789f0f79fc)\" d=\"M 37.51925 111.635849 \nL 146.521223 111.635849 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 41.80 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 114.785286)scale(0.088 -0.088)\">\n       <use xlink:href=\"#ArialMT-34\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-31\"/>\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-38\"/>\n       <use x=\"194.628906\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p789f0f79fc)\" d=\"M 37.51925 75.89493 \nL 146.521223 75.89493 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 41.85 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 79.044367)scale(0.088 -0.088)\">\n       <use xlink:href=\"#ArialMT-34\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-31\"/>\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-38\"/>\n       <use x=\"194.628906\" xlink:href=\"#ArialMT-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_8\">\n      <path clip-path=\"url(#p789f0f79fc)\" d=\"M 37.51925 40.15401 \nL 146.521223 40.15401 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 41.90 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 43.303448)scale(0.088 -0.088)\">\n       <defs>\n        <path d=\"M 350 1059 \nL 891 1109 \nQ 959 728 1153 556 \nQ 1347 384 1650 384 \nQ 1909 384 2104 503 \nQ 2300 622 2425 820 \nQ 2550 1019 2634 1356 \nQ 2719 1694 2719 2044 \nQ 2719 2081 2716 2156 \nQ 2547 1888 2255 1720 \nQ 1963 1553 1622 1553 \nQ 1053 1553 659 1965 \nQ 266 2378 266 3053 \nQ 266 3750 677 4175 \nQ 1088 4600 1706 4600 \nQ 2153 4600 2523 4359 \nQ 2894 4119 3086 3673 \nQ 3278 3228 3278 2384 \nQ 3278 1506 3087 986 \nQ 2897 466 2520 194 \nQ 2144 -78 1638 -78 \nQ 1100 -78 759 220 \nQ 419 519 350 1059 \nz\nM 2653 3081 \nQ 2653 3566 2395 3850 \nQ 2138 4134 1775 4134 \nQ 1400 4134 1122 3828 \nQ 844 3522 844 3034 \nQ 844 2597 1108 2323 \nQ 1372 2050 1759 2050 \nQ 2150 2050 2401 2323 \nQ 2653 2597 2653 3081 \nz\n\" id=\"ArialMT-39\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-34\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-31\"/>\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-39\"/>\n       <use x=\"194.628906\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 2.4 \nC 0.636487 2.4 1.246992 2.147121 1.697056 1.697056 \nC 2.147121 1.246992 2.4 0.636487 2.4 0 \nC 2.4 -0.636487 2.147121 -1.246992 1.697056 -1.697056 \nC 1.246992 -2.147121 0.636487 -2.4 0 -2.4 \nC -0.636487 -2.4 -1.246992 -2.147121 -1.697056 -1.697056 \nC -2.147121 -1.246992 -2.4 -0.636487 -2.4 0 \nC -2.4 0.636487 -2.147121 1.246992 -1.697056 1.697056 \nC -1.246992 2.147121 -0.636487 2.4 0 2.4 \nz\n\" id=\"m506a8ce3dc\" style=\"stroke:#1f77b4;stroke-width:0.8;\"/>\n    </defs>\n    <g clip-path=\"url(#p789f0f79fc)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"79.577739\" xlink:href=\"#m506a8ce3dc\" y=\"17.083636\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"100.79612\" xlink:href=\"#m506a8ce3dc\" y=\"37.795515\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"83.6307\" xlink:href=\"#m506a8ce3dc\" y=\"54.969323\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"74.479907\" xlink:href=\"#m506a8ce3dc\" y=\"56.807099\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"74.592484\" xlink:href=\"#m506a8ce3dc\" y=\"56.831541\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"68.991488\" xlink:href=\"#m506a8ce3dc\" y=\"58.700131\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"72.910031\" xlink:href=\"#m506a8ce3dc\" y=\"66.778034\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"90.334082\" xlink:href=\"#m506a8ce3dc\" y=\"61.814116\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"89.495896\" xlink:href=\"#m506a8ce3dc\" y=\"65.532979\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"87.43616\" xlink:href=\"#m506a8ce3dc\" y=\"67.177557\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"88.803824\" xlink:href=\"#m506a8ce3dc\" y=\"67.177557\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"107.100823\" xlink:href=\"#m506a8ce3dc\" y=\"73.482562\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"107.694733\" xlink:href=\"#m506a8ce3dc\" y=\"76.741948\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"103.47754\" xlink:href=\"#m506a8ce3dc\" y=\"74.130031\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"107.498475\" xlink:href=\"#m506a8ce3dc\" y=\"80.494514\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"111.029978\" xlink:href=\"#m506a8ce3dc\" y=\"80.722695\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"72.282556\" xlink:href=\"#m506a8ce3dc\" y=\"79.059851\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"96.314073\" xlink:href=\"#m506a8ce3dc\" y=\"85.326617\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"105.197107\" xlink:href=\"#m506a8ce3dc\" y=\"93.352316\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"107.297356\" xlink:href=\"#m506a8ce3dc\" y=\"92.346901\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"115.488393\" xlink:href=\"#m506a8ce3dc\" y=\"93.551394\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"117.599684\" xlink:href=\"#m506a8ce3dc\" y=\"93.599906\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"119.172712\" xlink:href=\"#m506a8ce3dc\" y=\"92.64468\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"107.157093\" xlink:href=\"#m506a8ce3dc\" y=\"105.299684\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"120.944126\" xlink:href=\"#m506a8ce3dc\" y=\"95.537522\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"118.748332\" xlink:href=\"#m506a8ce3dc\" y=\"97.366924\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"121.688292\" xlink:href=\"#m506a8ce3dc\" y=\"96.523537\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"118.183576\" xlink:href=\"#m506a8ce3dc\" y=\"101.569725\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"141.566588\" xlink:href=\"#m506a8ce3dc\" y=\"181.353039\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"106.503355\" xlink:href=\"#m506a8ce3dc\" y=\"166.92598\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"122.588852\" xlink:href=\"#m506a8ce3dc\" y=\"214.756364\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"123.956597\" xlink:href=\"#m506a8ce3dc\" y=\"214.514478\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"42.473885\" xlink:href=\"#m506a8ce3dc\" y=\"101.786233\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-width:0.8;\" x=\"94.411459\" xlink:href=\"#m506a8ce3dc\" y=\"184.946842\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 37.51925 224.64 \nL 37.51925 7.2 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 146.521223 224.64 \nL 146.521223 7.2 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 37.51925 224.64 \nL 146.521223 224.64 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 37.51925 7.2 \nL 146.521223 7.2 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p789f0f79fc\">\n   <rect height=\"217.44\" width=\"109.001973\" x=\"37.51925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAD5CAYAAAA0qJfgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATjElEQVR4nO3dfVDUVd/H8feuLMHiQ4rmU+ATVhYPiqnlaGhmY9pYeumNujJ0Z+HozGVWNj2MPf9jTTpOU5KaJK0NzaWjY+PUPU23Qs5tCD6RTBhCKnLjdWObCu6KsOzv/oNAQFh3lz3sb5fv65/rctltz8HP/M7x/M75/gyapmkIoZAx0A0QoU9CJpSTkAnlJGRCOQmZUE5CJpQLC3QDOnL8+PFAN0H4YOLEiR2+rsuQQecN7g4lJSWMGzcuYN+vguo+ubswyHAplJOQCeUkZEI5CZlQTkImlJOQ+ajC5uDn0stU2ByBboru6XYJQ8+25ZWTmVeO06URZjSwKmUMGSljAt0s3ZIrmZcqbA4y88q54migts7JFUcDmXnlckVzQ0LmpfM2O05X232eTpfGhb/sAWqR/knIvDQyOoowo6HNa2FGAyMGRAWoRfonIfNSbLSZVSlj6G820ScijP5mE6tnxBEbbQ5003RLJv4+yEgZw5z4oVz4y86IAVESsDuQkPkoNtos4fKQDJdCOQmZUE5CJpSTkAnlJGRCOQmZUE5CJpSTkAnlJGRCOQmZUE5CJpSTkAnlJGRCOQmZzoTiARXZ6qMjoXpAxaMr2Y4dO/joo48AqK+vJzU1Fbu97Z52u93OypUrWbp0KR9//DEAtbW1rFixgiVLlrB9+3Y/Nz20hPIBlTuG7OzZs/z4448AVFdX8/zzz3Px4sXb3rd7924mTZpETk4ORqORY8eOkZOTw8KFC8nJySE/P5/q6mr/9yBEhPIBFbcha2ho4LPPPmPVqlUA3Lhxg/fff58xY26/hJ87d44pU6YAEB8fz+nTpykqKmLSpEkYDAYmT55MUVGRgi6EhlA+oOJ2TvbFF1+QlpZGY2MjACNGjOj0vWPHjuXIkSMkJCRw5MgRhg4dyvXr1zGbm7YoR0ZG3jbEulNSUuLxe/2trq4uIN+/cFwfdhdfpdGl0cto4B/j+mCvvkCJHwaAQPUJ7hCyQ4cOUVBQQE1NDVevXmXKlCnMmDGjw/cuXryY9957j7S0NBITE+nXrx9RUVE4HA569+6Nw+Fg2LBhHjcskEXoAlUE7+1xkP64Q8kBlUAWwXMbsr179wJw9OhRcnNzOw0YwOnTp1myZAlJSUl88MEHTJw4katXr1JQUMC8efMoLCxkwYIFvvWgBwnFAypdXsLIzs4mMTGRmJgYXnrpJQCmTZvG/fffz5AhQ1i3bh07d+5k1qxZDB48uMsNFsHHoMdnKx0/flxqxvpZdwyXnf2dyYq/UE5CJpSTkAnlJGRCOQmZUE5CJpSTkAnlJGR+EoqbDf1FNi36QahuNvQXuZJ5IL/cxueHysgvt932s1DebOgvciW7g+e/KuDQ75fRAAMw8/5BZP3n5Jafu9tsGGo3un0lV7J2KmwOjv+vgwqbg/xyW0vAADTg0O+X21zRQnmzob/IlayV5rlVfYOTjUdsJN57N+13D2jAiYtXeGRMNHCrGnbrOZlUw25LQva31nMrAHtDA8cvXLntfQYgOaZ/m9ekGrZ7ErK/dTS3Mhhg/L39KKq81jIne/yBe1quYq2522xYYXNw3mZnZHTPDKCE7G+dza0+XZpM1dUbnLh4heSY/h0GzB1Z3pCQtWg9t6pvcBJuCmuZW8VGm70OF9w+BANk5pUzJ35oj7qiSchaaZ5bHT5VwvTx47ochPM2O/VOV5vXeuLyhixhtBMbbSZ5mH8Oc/xSbsNR39jmtZ64vCEhuwNf70nml9uw5p9vswRiAJZOju1RVzGQ4dItXyft2/LK+fTgWa7fvP0q9qgPc7tgJ1eyTvh6T7L5c+0DBk3zMZOx5/3Ke16PPeRrAZSOPtcsPMxIg8vV4c9CmYSsE77ek+zoc83M4b163KQfJGSd8vUJva0/d1eYAQNwV5ixRz/hVyb+bvh6T7L150zGpiGyq/c0g/nWlITsDnwtgNLVwimtQ/VfxZeC+taURyHbsWMHf/75J6+//jr19fWkpaWRlZVFVNSt+cXNmzdZs2YNNTU1PPTQQ6xfv57a2lqeeuopRo0aBcCmTZsYNGiQmp6EkNZLJwagvtFFXcOtfzAE260pv5XzPHz4MHFxceTk5FBdXU15eTmlpaUsWrQIq9WK1WqVgHmg/dJJTZ2zTcAg+Mp8+q2cZ1xcHC6XC03TuHHjBmazmdLSUvLz87FYLGzdulVND0KMuyWQZsF2a8ptyJrLeUZGRgJN5Tw7ChhAr169OHToEHPmzKGxsZEhQ4YQGxvLunXrsFqtnD59mlOnTvm9A6GmoyUQU6s/G4AJsf2DZqgEP5bz3LVrFy+88AKLFi1i48aNfPfdd8yePZuIiAiMRiNTp06lrKyM8ePHe9QwPdSMvVTbQFVNA8P6mhjax9Rt39+6diwGA87GW8OlBhw79ycHC371qk26rRnrTTlPs9ncUoR44MCB2O12PvnkE6ZPn87MmTM5ceIE6enpHjcs0DVjD1eHk5l3MSD/omtdO/b/rtXx/oHfuNnobPm5ZjBi6j+UcWM9n+MGsmZslxdjs7OzOXnyJGlpaezbt4/ly5dTUFDAggULyMjIICsrC4vFQkxMDAkJCV39um5xqbYh4GcpY6PNTB87iMmjomlobDvxb2h0YTIag+bEukdLGFOmTGmp0Q9gtVpb/n/rq1P7p45ERka2eW+wqKpp0NVZyvY3qZyNLjKsx9AgKNbN5LZSB4b1NenmLOV5m52wXm3/mpwuqKlzBs2JdQlZB4b2Mfl031IFdzfcm+l93UxuK3WiO85SenI/sv3hYQNNc7IbrRZo9b5uJiFzQ+WDG7zZdds+8O3vZep9d4eELAB8OSrXOvDBdmJdQhYA/qgEFEyPx5GJfwD0tEpAErIA8HXXbbCS4TJAgm1e1RUSsgDyZl4l26+FMhU2B1tyy/j+9CW3t5GaQxjey0h9o6vlf/UQSgmZjm3LK+ezQ2XU1DnbvN5+uaN5zc1R76TeqWE0gEtrOudpDu/FqpQxTL8nED1oIhN/nWpeS2sfMGh7G6n1mttNp4YGNGpN+85uOl1ccTTw6cGzFP37Rvd2oBUJmU6524bdernDk+3a12828t5/X2JbXrnf2+kJCZlOdXZjvG9EWJvlDk9uoAPUOWHTT6UB2a0hIdOp9mtpfSPCWDophgP/nM6Lj43u8H13hbkPW12Di8Lztz/wQjWZ+OuYp2tpze8rPG/j3e9+4/rN2+dxt9z5qudvEjKd83QtLTbazHmbHYObDEWajEwaOcCPrfOMhCyEdDY/izAZ6WWAtU/cH5A1s6AIWTCvdnen2GgzE2LubvMsqEdGD2D1zDgarlzi8cmj7/SfUEL3IZM6+J6rsDk4efFqm2dBnfl3LSMGRGF3dt+50fZ0/a9Lecyfd3ytDqmarkOm119aIHhShVuv+9R0PVzq9ZfW3TydMrh7Yl1JdQAa/jddh0we8+f9eQA97lPTdchAn7+07uTLeQC97f/XfchAf7+07hQKUwZdT/xFaJwHUF4zdu3atdjtdmbNmsWLL76orCOhLNinDEprxubk5LBw4UJycnLIz8+nujqA/8QJcs2lpIItYKC4ZmxRURGTJk3CYDAwefJkioqK1PRC6Jrb4bK5ZmxjY9PDqEaMGNHpe5trxh48eJDhw4czZMgQrl+/3lJ9MTIyErvd80VUPZTzDCW6LefZ1ZqxUVFROBwOevfujcPhYNiwYR43LNDlPAP5/SoEspyn0pqx8fHxFBQUMG/ePAoLC1mwYIEPzRfBTmnNWIvFwv79+1m8eDEPP/wwgwcP9kebRZAxaJrm/qhLABw/fpyJEycG7PtluPSeu78zWYwVyknIhHISMqGchEwoJyETyknIhHISMqGchEwoJyETyknIhHISMqGchEwoJyETyknIhHISMqGchEwoJyETyknIhHISMqGchEwoJyETyknIhHISMqGchEwoJyETyknIhHISMqGchEwo57easdu2bePw4cNAUwnQ9evXExcXx+rVqxk+fDgAVqtVQReE3vmtZmxGRgZWq5UNGzbwwAMPMHfuXEpLS1m1ahVWq1UC1oP5rWZssy1btrBmzRqMRiOlpaUcOHCAZcuWsWfPHv+2XAQNv9WMhaa6pFVVVSQnJwPw4IMP8uyzzxIbG0t6ejrTpk1jyJAhHjVMasb6V0jUjAXIzc0lJSWl5c+PPfYYvXv3BiA5OZlz5855HDKpGetfgawZ63a43Lt3L1arlbfeeou5c+e6DRg01ZZNSkpq+fOrr75KaWkpLpeL4uJit8OsCF1dfrZSdnY2iYmJTJgwgcrKyjYVrl9++WXeeecdDAYDzzzzDPfcc09Xv04EIakZ2wEZLr0nNWNFQEnIhHISMqGchEwoJyETyknIhHISMqGchEwoJyETyknIhHISMqGchEwoJyELAhU2Bz+XXqbC5gh0U3zS5a0+Qq1teeVk5pXjdGmEGQ2sShlDRkpw7cuTK5mOVdgcZOaVc8XRQG2dkyuOBjLzyoPuiiYh07HzNjtOV9vtfk6XxoW/7AFqkW8kZDo2MjqKMKOhzWthRgMjBkR18gl9kpDpWGy0mVUpY+hvNtEnIoz+ZhOrZ8QRG20OdNO8IhN/nctIGcOc+KFc+MvOiAFRQRcwkJAFhdhoc1CGq5kMl0I5CZlQTkImlJOQCeUkZEI5CZlQTkImvOLLjhBZJxMe83VHiEdXsh07dvDRRx8BUF9fT2pqKnZ725u027ZtIy0tjbS0NB555BEOHDjApUuXsFgspKamsn//fh+6JfSiKztClNaMzczM5LXXXsNqtZKTk0N9fb0P3RN60JUdIUprxp45c4akpCTCw8O57777KCsr86Q/IS8Yd7p2ZUeI0pqxLpcLg6GpYZGRkTgcnv9SQ7Vm7J7iq/yr+Coul4bRaOA/4u9mUfzdSr6rNX/0aeG4PuwuvkqjS6OX0cA/xvXBXn2Bkmr3n1NaM9ZovHWhdDgcLfVjPRGKNWMrbA72llyk9qbr71c09pbUkv54kvIb4P7o09vjIP1xR4c7QtzVjHUbsr179wJNtWBzc3M9qhk7f/78lj+PHTuWkydPEh8fz++//87o0aM96UvIcjevCZZdFr7sCFFaM3b16tW88cYb2O12LBYL4eHhXf26oBYqO129JTVjO6Cyvmr7tabVM+J48TH1V/hA1oyVxdhuFgo7Xb0lIQuAYN/p6i25dymUk5AJ5SRkQjkJmVBOQiaUk5AJ5SRkQjkJmVBOQiaUk5AJ5SRkQjkJmVBOQiaUk5AJ5SRkQjkJmVBOQiaUk5AJ5SRkQjkJmVBOQiaUk5D1IIEq9CJH4nqACpuDzf9TzS+VFWjQ7Y80lJCFuG155Xx2qIyaOmeb1zPzypkTP7Rbzn/KcBnCmqsjtg8YdO8jDf1WzlPTND744AMsFgsrVqzAbrdTW1vLtGnTWsp8Xr582f89EJ3qqIpQs+4s9HLH4bK5nGdycjLV1dW88sorHZbzzM3NJSIigm+++YaffvqJqqoqampqWLRoEWvXrlXRdnEHHVURAugbEdatjzT0WznPwsJCTCYTzz33HAUFBcTFxVFaWkp+fj4Wi4WtW7eq6YHoVOvnZUaZDPSNCGPppBgO/HN6t1QSaua3cp7Xrl3DZDKxc+dO3n33XXJzc4mNjWXdunUkJyezZs0aTp06xfjx4/3aAeFecxWhw6dKmD5+XEAKvfitnGffvn2ZMGECAI8++ihnz55l+fLlREREYDQamTp1KmVlZR6HLFRrxgbKgwOMHtV3VcFv5TwTExMpLCzkySefpLi4mISEBD755BOmT5/OzJkzOXHiBOnp6R43LBRrxgZSdxTB60yXlzCys7M5efIks2fPpra2ltTUVKqqqnjiiSfIyMggKysLi8VCTEwMCQkJXf06EYSknGcH5ErmPXd/Z7IYK5STkAnldDtciuDT2XCpy5CJ0CLDpVBOQiaUk5AJ5SRkQjkJmVBOQiaU67F7/DVN48033+TChQsMHjyYjRs3smPHDg4fPgw0bdZcv349Tz/9NNC0WWDfvn0AVFRUsGzZMlauXBmw9nfE2z4BZGZm8vPPP2M0Gtm0aRODBw9W0rAe6bffftNeeuklTdM0bcOGDVpubm7LzyorK7X09HStsbHxts/V1tZqqampmt1u766meszbPp05c6bl/YWFhVpBQYGSdvXY4fLee+8lIiICTdOw2+1ERd3a775lyxbWrFnT5vHWzb7++mssFgtms/6e8uZtn44dO8agQYNYsWIFe/bsITExUUm7esxw+e2337bsjwNISUnhjz/+YM6cOYSHh7N+/XqgacNiVVUVycnJHf53fvnlFzIyMrqlzXfS1T5du3aNixcvsn37dr788kt2797N8uXL/d9QJdfHIJCdna1t3rxZ0zRNy8nJ0T7//HNN0zTthx9+0L766qsOP/Prr79qH374YXc10Wve9mnXrl1aVlaWpmlNfXv77beVtKvHDpdms7llyBs4cGDLEb+jR4+SlJTU4WeOHj2q6zMK3vYpISGBwsJCAIqLixk5cqSSdvWY4bK9+fPn89prr2GxWIiIiGDDhg0AVFZWMmzYsJb3ff/995hMJmbPnk1lZWXLOQY98qVPo0aNYvHixfTr14/NmzcraZfswhDK9djhUnQfCZlQTkImlJOQCeUkZEI5CZlQTkImlJOQCeX+HzJbnWjlaJlnAAAAAElFTkSuQmCC"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many tracts intersect with public data? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "df_final_psm[df_final_psm.gisjoin.isin(gpd.sjoin(df_final_psm,\n",
    "                                         public_data).gisjoin.unique())].shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keep the tracts that don't have any public data. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "df_final_psm = df_final_psm[~df_final_psm.gisjoin.isin(gpd.sjoin(df_final_psm,\n",
    "                                                                public_data).gisjoin.unique())]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Pre-Treatment\n",
    "Select and average over pre-treatment period "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_psm = df_final_psm[(df_final_psm.period=='pre')]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_psm = df_final_psm.groupby(['period','gisjoin']).mean().reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Join back with FHA and HOLC Labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_psm = df_final2[df_final2.year==1940][['gisjoin','fha_grade','holc_grade','geometry']].merge(df_final_psm,on='gisjoin')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 Join with neighorhood boundaries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "neighorhoods = gpd.read_file('data/chicago_neighborhoods/Neighborhoods_2012b.shp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tract_n_labels = gpd.overlay(df_final_psm,neighorhoods[['PRI_NEIGH', 'SEC_NEIGH', 'geometry']].to_crs({'init': 'epsg:4326'}))\n",
    "tract_n_labels['overlay_area']=tract_n_labels.geometry.area\n",
    "tract_n_labels = tract_n_labels.sort_values(['gisjoin','overlay_area'],ascending=False)\\\n",
    "                                .groupby('gisjoin')\\\n",
    "                                .first()\\\n",
    "                                .reset_index()\n",
    "            \n",
    "df_final_psm = df_final_psm.merge(tract_n_labels[['gisjoin','PRI_NEIGH','SEC_NEIGH']],on='gisjoin',how='left')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Create a new DF that averages over periods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_avg = df_final2[df_final2.year==1940][['gisjoin','fha_grade','D_fha','holc_grade','geometry']]\\\n",
    "                                                    .merge(df_final2.groupby(['gisjoin','period'])\\\n",
    "                                                                   .mean()\\\n",
    "                                                                   .reset_index(),\n",
    "                                                   on='gisjoin')\n",
    "df_final_avg1 = df_final_avg.merge(df_final_psm[['white_perc_chng','black_perc_chng','population_density_chng_perc',\n",
    "                                                 'population_chng_perc','ln_median_homevalue_adj_chng_perc',\n",
    "                                                 'owned_perc_chng','e_w_chng_perc','gisjoin']],on='gisjoin')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_avg1_export = df_final_avg1.copy()\n",
    "df_final_avg1_export.to_postgis('df_final_avg', engine, if_exists='replace')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Background Values and Charts for Paper"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Test for spatial autocorrelation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from esda.moran import Moran\n",
    "\n",
    "for i in ['ln_median_homevalue_adj','owned_perc','e_w']:\n",
    "    print(i)\n",
    "    for y in df_final_avg1.period.unique():\n",
    "        W = ps.weights.Queen.from_dataframe(df_final_avg1[df_final_avg1.period==y].to_crs(epsg=3857),ids='gisjoin',geom_col='geometry')\n",
    "        mi = Moran(df_final_avg1[df_final_avg1.period==y][i].values, W, two_tailed=True)\n",
    "        print(\"%.3f\"%mi.I,\"%.5f\"%mi.p_norm, \"%.3f\"%mi.EI)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Test for temporal autocorrelation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a sorting order to autocorrelation purposes\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_avg1.loc[df_final_avg1.period=='pre','per_order'] = 1\n",
    "df_final_avg1.loc[df_final_avg1.period=='post','per_order'] = 2\n",
    "df_final_avg1.loc[df_final_avg1.period=='reversal','per_order'] = 3\n",
    "\n",
    "df_final_avg1 = df_final_avg1.sort_values(['gisjoin','per_order'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "row = 0\n",
    "fig,ax = plt.subplots(3,4,figsize=(24,14))\n",
    "for i in ['ln_median_homevalue_adj','owned_perc','e_w']:\n",
    "    counter = 0\n",
    "    for grade in ['A','B','C','D']:\n",
    "        \n",
    "        plot_acf(df_final2[(df_final2['fha_grade']==grade)][i].fillna(0), \n",
    "                 lags=7,\n",
    "                 ax =ax[row][counter],\n",
    "                 title='Autocorr: Grade {} | {}'.format(grade,i))\n",
    "        ax[row][counter].set_xlabel('Years after 1930')\n",
    "        counter +=1\n",
    "    row+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "row = 0\n",
    "fig,ax = plt.subplots(3,4,figsize=(24,11))\n",
    "for i in ['ln_median_homevalue_adj','owned_perc','e_w']:\n",
    "    counter = 0\n",
    "    for grade in ['A','B','C','D']:\n",
    "        \n",
    "        plot_acf(df_final_avg1[(df_final_avg1.fha_grade==grade)][i].fillna(0), \n",
    "                 lags=2,\n",
    "                 ax =ax[row][counter],\n",
    "                 title='Autocorr: Grade {} | {}'.format(grade,i))\n",
    "        counter +=1\n",
    "    row+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Trends over Time\n",
    "\n",
    "This plot looks at the FHA labels and tracks them over time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.set_context(\"paper\")\n",
    "\n",
    "summary_features = [ 'population','population_density','unemployed_perc',\\\n",
    "              'black_perc','white_perc','asian_perc','hispanic_perc',\n",
    "                 'college_perc','owned_perc','homes','median_homevalue_adj','e_w']\n",
    "\n",
    "df_final_plots = df_final2.replace(0,np.nan)\n",
    "f, axes = plt.subplots(4, 3, figsize=(14, 12), sharex=True)\n",
    "sns.despine(left=True)\n",
    "for i,each in enumerate(summary_features):\n",
    "    if i==0: \n",
    "        l = 'brief'\n",
    "    else: \n",
    "        l=False\n",
    "    \n",
    "    a1=i%4\n",
    "    a2 = int(i/4)\n",
    "    sns.lineplot(x='year',\n",
    "                 y=each,\n",
    "                 data=df_final_plots[df_final_plots.year!=1950],\n",
    "                 hue='fha_grade',\n",
    "                 hue_order=['A','B','C','D'],\n",
    "                 palette={\"A\":\"#5FCE72\",\"B\":\"#0BC0ED\",\"C\":\"#FFD419\",\"D\":\"#FF4B19\"},\n",
    "                 legend=l,err_style='bars',\n",
    "                 ax=axes[a1,a2],estimator=np.mean)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 Pre-Treatment Choropleth\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(20,8))\n",
    "\n",
    "df_final_avg1[df_final_avg1.period=='pre'].plot('ln_median_homevalue_adj',cmap='viridis_r', ax=ax[0], legend=True, linewidth=0.1,scheme='quantiles')\n",
    "df_final_avg1[df_final_avg1.period=='pre'].plot('owned_perc',cmap='viridis_r', ax=ax[1], legend=True, linewidth=0.1,scheme='quantiles')\n",
    "df_final_avg1[df_final_avg1.period=='pre'].plot('e_w',cmap='viridis_r', ax=ax[2], legend=True, linewidth=0.1,scheme='quantiles')\n",
    "\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[2].set_axis_off()\n",
    "\n",
    "\n",
    "ax[0].set_title('Pre-Treatment Log Median Home Value')\n",
    "ax[1].set_title('Pre-Treatment Ownership Percentage')\n",
    "ax[2].set_title('Pre-Treatment Spatially Weighted Entropy Index')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 FHA/HOLC Comparison\n",
    "- A count of which tracts are labeled the same vs different. \n",
    "- When different, how is it different? \n",
    "- Side by side map comparison"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fha_holc_test = df_final2[(df_final2.period=='pre') &\n",
    "                           (df_final2.holc_grade.isin(['A','B','C','D']))][['fha_grade','holc_grade','gisjoin_1940']]\n",
    "df_fha_holc_test['holc_grade_new'] = df_fha_holc_test['holc_grade'].apply(lambda x: x[0])\n",
    "\n",
    "df_fha_holc_test['same'] = df_fha_holc_test.apply(lambda x: 'y' if x['holc_grade']==x['fha_grade'] else 'n',axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that most of the FHA and HOLC labels are the same."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fha_holc_test.groupby('same').count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we can see how the two maps are different."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,10))\n",
    "    \n",
    "for label, data in df_final2[(df_final2.year==1940)\\\n",
    "                             &(df_final2.fha_grade.isna()==False)].groupby('fha_grade'): \n",
    "    color = paper_cmap[label]\n",
    "    data = gpd.GeoDataFrame(data,geometry='geometry',crs=4326).to_crs(epsg=3857)\n",
    "    data.to_crs(epsg=3857).plot(color=color,ax=ax1, label=label, legend=False, linewidth=0.1,)\n",
    "    \n",
    "for label, data in df_final2[(df_final2.year==1940)\\\n",
    "                             &(df_final2.holc_grade.isna()==False)].groupby('holc_grade'): \n",
    "    color = paper_cmap[label]\n",
    "    data = gpd.GeoDataFrame(data,geometry='geometry',crs=4326).to_crs(epsg=3857)\n",
    "    data.plot(color=color,ax=ax2, label=label, legend=True, linewidth=0.1)\n",
    "    \n",
    "df_final2[(df_final2.year==1940)\\\n",
    "          &(df_final2.fha_grade.isna()==False)\\\n",
    "          &(df_final2.holc_grade!=df_final2.fha_grade)].to_crs(epsg=3857).plot(ax=ax1, facecolor=\"none\", \n",
    "              edgecolor=\"gray\", lw=0.7,linestyle='--')\n",
    "df_final2[(df_final2.year==1940)\\\n",
    "          &(df_final2.fha_grade.isna()==False)\\\n",
    "          &(df_final2.fha_grade!=df_final2.holc_grade)].to_crs(epsg=3857).plot(ax=ax2, facecolor=\"none\", \n",
    "              edgecolor=\"gray\", lw=0.7,linestyle='--')\n",
    "\n",
    "  \n",
    "ax2.set_title('Tract Labels by HOLC Map')\n",
    "ax1.set_title('Tract Labels by FHA Map')\n",
    "ax1.set_axis_off()\n",
    "ax2.set_axis_off()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Propensity Score Matching"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Features to run the propensity scoring"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pscore_features= ['white_perc','white_perc_chng','black_perc','black_perc_chng',\n",
    "                'population_density','population_density_chng_perc',\n",
    "                'population','population_chng_perc',\n",
    "                'college_perc','ln_median_homevalue_adj','ln_median_homevalue_adj_chng_perc',\n",
    "                'owned_perc','owned_perc_chng','perc_college_10plus','perc_black_20plus','dist_downtown','e_w','e_w_chng_perc']\n",
    "\n",
    "pscore_features_chng = ['ln_median_homevalue_adj_chng_perc',\n",
    "                  'owned_perc_chng','e_w_chng_perc']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_psm['fha_grade_psm'] = df_final_psm.apply(lambda x: 'D' if x['fha_grade']=='D' else 'not_D',axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 Estimate weights\n",
    "Weights will probably be slightly different each time and resulting tracts that remain also different. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "### Process the data\n",
    "le = preprocessing.LabelEncoder()\n",
    "scaler =preprocessing.MinMaxScaler()\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "### Fill missing values with the column mean\n",
    "X = df_final_psm[pscore_features]\n",
    "X = X.fillna(value=X.mean(axis=0)) \n",
    "\n",
    "##### Transform all to 0-1 scale.\n",
    "X1 = pd.DataFrame(data=std_scaler.fit_transform(X,),columns=X.columns, index=X.index)\n",
    "\n",
    "X1 = pd.merge(df_final_psm[['fha_grade_psm']],\n",
    "              X1,left_index=True,right_index=True)\n",
    "X1 = X1[pscore_features]\n",
    "\n",
    "y = le.fit_transform(df_final_psm['fha_grade_psm'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "rf= RandomForestClassifier()\n",
    "rf1 = CalibratedClassifierCV(rf, cv=5,method='isotonic')\n",
    "\n",
    "\n",
    "rf1 = rf1.fit(X1,y)\n",
    "rf = rf.fit(X1,y)\n",
    "\n",
    "print(\"Mean acccuracy of RF {:.3f}\".format(rf1.score(X1, y)))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### RF\n",
    "y_probs = cross_val_predict(rf1, X1, y,cv=5,method='predict_proba')\n",
    "df_final_psm['{}_prob'.format(le.classes_[0])]= y_probs[:,0]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X1.columns,\n",
    "                                    columns=['importance']).sort_values('importance',  ascending=False)\n",
    "\n",
    "feature_importances"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 Turn probabilities into propensity weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_psm.loc[df_final_psm['D_prob']==1,'D_prob']=.999999\n",
    "df_final_psm.loc[df_final_psm['D_prob']==0,'D_prob']=.000001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "weights_name='weights3'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_final_psm[weights_name] = df_final_psm.apply(lambda x: 1/x['D_prob'] if x['fha_grade_psm']=='D' else 1/(1-x['D_prob']),axis=1)\n",
    "df_final_psm[weights_name] = df_final_psm[weights_name].apply(lambda x: 100 if x>100 else x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3 Filter years and PSM \n",
    "\n",
    "Filter for years that are not 1950 and also here's the place to filter for more stringent conditions such as \n",
    "- Tracts with non-black neighbors\n",
    "- D-probs below a certain treshold. (using 25% here)\n",
    "- Also find the non-D tracts that have a high prob of being D and were not??\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "** Filter for probabilties**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##### create a DF with just the tract pairs\n",
    "def final_df(weights_col,d_t=.9):\n",
    "    D_thres = d_t\n",
    "\n",
    "    df_allyrs= df_final_avg1[\n",
    "                ((df_final_avg1['gisjoin'].isin(df_final_psm[(df_final_psm['D_prob']<=D_thres)\\\n",
    "                                                             &(df_final_psm['fha_grade_psm']=='D')].gisjoin.values))\n",
    "                 | \\\n",
    "                 (df_final_avg1['gisjoin'].isin(df_final_psm[(df_final_psm['D_prob']>=(1-D_thres))\\\n",
    "                                                             &(df_final_psm['fha_grade_psm']!='D')].gisjoin.values))\n",
    "                )\n",
    "                     &\\\n",
    "                (df_final_avg1['gisjoin'].isin(df_final_psm[df_final_psm[weights_col]<=100].gisjoin.values))\n",
    "               ]\n",
    "\n",
    "    df_allyrs_norm=pd.merge(df_allyrs,df_final_psm[['gisjoin',weights_col,'PRI_NEIGH']],how='left',on='gisjoin')\n",
    "    return(df_allyrs_norm)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_allyrs_norm = final_df(weights_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\n",
    "holc_weights= gpd.read_file('data/holc_weights/holc_weights.shp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12, 6))\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "chicago_boundary = gpd.read_file('data/chicago_boundary/geo_export_f05488dc-4f9d-49be-81e3-c094992d4c80.shp')\n",
    "\n",
    "chicago_boundary.plot(ax=ax[0],color='white',edgecolor='#454545',linewidth =.4,)\n",
    "chicago_boundary.plot(ax=ax[1],color='white',edgecolor='#454545',linewidth =.4,)\n",
    "\n",
    "for label, data in df_allyrs_norm[df_allyrs_norm.period=='pre'].groupby('fha_grade'): \n",
    "    color = paper_cmap[label]\n",
    "    data.plot(color=color,ax=ax[0], label=label, legend=True,linewidth=0.1)\n",
    "    \n",
    "for label, data in holc_weights[holc_weights.period=='pre'].groupby('holc_grade'): \n",
    "    color = paper_cmap[label]\n",
    "    data.plot(color=color,ax=ax[1], label=label,linewidth=0.1)\n",
    "\n",
    "\n",
    "ax[0].set_title('D-nD FHA tracts {} threshold'.format(0.9))\n",
    "ax[1].set_title('D-nD HOLC tracts {} threshold'.format(0.9))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[0].legend()\n",
    "\n",
    "# plt.savefig('results/fha_holc_sidebyside_map.png',bbox_inches = 'tight',\n",
    "#     pad_inches = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4 Compare D against non-D and C, using weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def wavg(group, avg_name, weight_name):\n",
    "    \n",
    "    \"\"\" http://stackoverflow.com/questions/10951341/pandas-dataframe-aggregate-function-using-multiple-columns\n",
    "    In rare instance, we may not have weights, so just return the mean. Customize this if your business case\n",
    "    should return otherwise.\n",
    "    \"\"\"\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum() / w.sum()\n",
    "#         return d.mean()\n",
    "    except ZeroDivisionError:\n",
    "        return d.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is what the two groups look like now once we've adjusted for the weights. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.4.1 Find best threshold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pscore_features_chng = ['ln_median_homevalue_adj_chng_perc', 'owned_perc_chng', 'e_w_chng_perc']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import scipy\n",
    "d_nd_dist = []\n",
    "d_c_dist = []\n",
    "\n",
    "thres_range = np.arange(0.1,1,.01)\n",
    "\n",
    "for i in thres_range:\n",
    "    df_allyrs_norm = final_df(weights_name,d_t=i)\n",
    "\n",
    "    df_wavg = pd.DataFrame(columns = pscore_features_chng,index= ['D', 'not_D_fha'])\n",
    "    for each in pscore_features_chng: \n",
    "        df_wavg.loc[:,each] = df_allyrs_norm[df_allyrs_norm.period=='pre'].groupby(\"D_fha\").apply(wavg, each,weights_name).values\n",
    "        \n",
    "        \n",
    "    df_wavg = df_wavg.transpose()\n",
    "    \n",
    "    d_nd_dist.append(scipy.spatial.distance.pdist(df_wavg.transpose())[0])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(thres_range,d_nd_dist,label='D-nD')\n",
    "plt.title('Sum of differences between two FHA groups')\n",
    "plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "thres =.9\n",
    "\n",
    "df_allyrs_norm = final_df(weights_name,d_t=thres)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.5 Compare FHA and HOLC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "holc_weights = gpd.read_file('data/holc_weights/holc_weights.shp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t = df_allyrs_norm[(df_allyrs_norm.period=='pre') \\\n",
    "                   &(df_allyrs_norm.holc_grade.isin(['A','B','C','D']))][['fha_grade','holc_grade','gisjoin','geometry',weights_name]]\n",
    "\n",
    "df_fha_holc_subgroup = pd.merge(t,df_final_psm[['gisjoin','D_prob']],on='gisjoin')\n",
    "df_fha_holc_subgroup['holc_grade_new'] = df_fha_holc_subgroup['holc_grade'].apply(lambda x: x[0])\n",
    "df_fha_holc_subgroup['same'] = df_fha_holc_subgroup.apply(lambda x: 'y' if x['holc_grade']==x['fha_grade'] else 'n',axis=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "holc_propensity_weights = holc_weights[holc_weights.period=='pre'].rename(columns={'D_prob':'holc_D_prob'})[['gisjoin','PRI_NEIGH','holc_D_prob']],\n",
    "df_fha_holc_subgroup = pd.merge(df_fha_holc_subgroup,\n",
    "                                holc_propensity_weights,\n",
    "                                on='gisjoin',\n",
    "                                how='left')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fha_holc_subgroup.groupby(['same','fha_grade','holc_grade']).count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compare FHA and HOLC Weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12, 6))\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "chicago_boundary = gpd.read_file('data/chicago_boundary/geo_export_f05488dc-4f9d-49be-81e3-c094992d4c80.shp')\n",
    "\n",
    "chicago_boundary.plot(ax=ax[0],color='white',edgecolor='#454545',linewidth =.4,)\n",
    "chicago_boundary.plot(ax=ax[1],color='white',edgecolor='#454545',linewidth =.4,)\n",
    "\n",
    "\n",
    "pd.merge(df_allyrs_norm[(df_allyrs_norm.period=='pre')&(df_allyrs_norm.weights3<100)],df_final_psm[['gisjoin','D_prob']],on='gisjoin').plot('weights3',\n",
    "                                                                                                              legend=True,\n",
    "                                                                                                              ax=ax[0],\n",
    "                                                                                                             cmap='GnBu',\n",
    "                                                                                                              scheme='quantiles',\n",
    "                                                                                                              linewidth=0.1)\n",
    "\n",
    "holc_weights.plot('weights_holc',legend=True,ax=ax[1],cmap='GnBu',scheme='quantiles',linewidth=0.1)\n",
    "\n",
    "\n",
    "\n",
    "ax[0].set_title('FHA Weights'.format(0.9))\n",
    "ax[1].set_title('HOLC Weights'.format(0.9))\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Look at low probabilty D Tracts - FHA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(12, 6))\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "chicago_boundary = gpd.read_file('data/chicago_boundary/geo_export_f05488dc-4f9d-49be-81e3-c094992d4c80.shp')\n",
    "\n",
    "chicago_boundary.plot(ax=ax,color='white',edgecolor='#454545',linewidth =.4,)\n",
    "\n",
    "df_fha_lowprobD = pd.merge(df_allyrs_norm[(df_allyrs_norm.period=='pre')&\\\n",
    "                        (df_allyrs_norm.weights3<100)&\\\n",
    "                        (df_allyrs_norm.fha_grade=='D')],df_final_psm[['gisjoin','D_prob']],on='gisjoin')\n",
    "\n",
    "df_fha_lowprobD=df_fha_lowprobD[df_fha_lowprobD['D_prob']<.5]\n",
    "\n",
    "neigh_fiveormorecount = df_fha_lowprobD.groupby('PRI_NEIGH').count().sort_values('gisjoin',ascending=False).reset_index().reset_index()\n",
    "\n",
    "## Plot Neighborhoods that include these tracts\n",
    "neighborhoods_example = neighorhoods[neighorhoods.PRI_NEIGH.isin(neigh_fiveormorecount.PRI_NEIGH)].to_crs({'init':'epsg:4326'})\n",
    "neighborhoods_example['coords'] = neighborhoods_example['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "neighborhoods_example['coords'] = [coords[0] for coords in neighborhoods_example['coords']]\n",
    "for idx, row in neighborhoods_example.iterrows():\n",
    "    plt.annotate(s=row['PRI_NEIGH'], xy=row['coords'],\n",
    "                 horizontalalignment='center',)\n",
    "    \n",
    "neighborhoods_example.plot(ax=ax,color='white',edgecolor='#454545',linewidth =.4,)\n",
    "\n",
    "\n",
    "df_fha_lowprobD.plot('D_prob',\n",
    "                      legend=True,\n",
    "                      ax=ax,\n",
    "                     cmap='viridis',\n",
    "                      scheme='Quantiles',k=5,\n",
    "                      linewidth=0.1)\n",
    "\n",
    "\n",
    "ax.set_title('Probability of D label - FHA D Tracts'.format(0.9))\n",
    "ax.set_axis_off()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracts with different FHA and HOLC Labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12, 6))\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "chicago_boundary = gpd.read_file('data/chicago_boundary/geo_export_f05488dc-4f9d-49be-81e3-c094992d4c80.shp')\n",
    "\n",
    "chicago_boundary.plot(ax=ax,color='white',edgecolor='#454545',linewidth =.4,)\n",
    "\n",
    "\n",
    "df_fha_diff=df_fha_holc_test_subgroup_paper[(df_fha_holc_test_subgroup_paper.same=='n')&\\\n",
    "                                (df_fha_holc_test_subgroup_paper.fha_grade=='D')]\n",
    "\n",
    "\n",
    "## Plot Neighborhoods that include these tracts\n",
    "neighborhoods_example = neighorhoods[neighorhoods.PRI_NEIGH.isin(df_fha_diff.PRI_NEIGH)].to_crs({'init':'epsg:4326'})\n",
    "neighborhoods_example['coords'] = neighborhoods_example['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "neighborhoods_example['coords'] = [coords[0] for coords in neighborhoods_example['coords']]\n",
    "for idx, row in neighborhoods_example.iterrows():\n",
    "    plt.annotate(s=row['PRI_NEIGH'], xy=row['coords'],\n",
    "                 horizontalalignment='center')\n",
    "    \n",
    "neighborhoods_example.plot(ax=ax,color='white',edgecolor='#454545',linewidth =.4,)\n",
    "\n",
    "\n",
    "df_fha_diff.plot('D_prob',\n",
    "                      legend=True,\n",
    "                      ax=ax,\n",
    "                     cmap='viridis',\n",
    "                      scheme='Quantiles',k=5,\n",
    "                      linewidth=0.1)\n",
    "\n",
    "\n",
    "ax.set_title('Probability of D label - FHA D Tracts not graded D by HOLC'.format(0.9))\n",
    "ax.set_axis_off()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. DiD analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "df_final_psm[df_final_psm.fha_grade_psm=='D']['{}_prob'.format(le.classes_[0])].hist(bins=30,density=True,alpha=.5,label='D')\n",
    "df_final_psm[df_final_psm.fha_grade_psm=='not_D']['{}_prob'.format(le.classes_[0])].hist(bins=30,density=True,alpha=.5,label='non-D')\n",
    "\n",
    "plt.vlines(thres,0,16,linestyles='dashed',color='C0',lw=2.5,alpha=0.5,label='D threshold')\n",
    "plt.vlines(1-thres,0,16,linestyles='dashed',color='C1',lw=2.5,alpha=0.5,label='non-D threshold')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Tracts Used Given Probability of D FHA Grade')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_wavg = pd.DataFrame(columns = pscore_features_chng,index= ['D', 'not_D_fha'])\n",
    "\n",
    "for each in pscore_features_chng: \n",
    "    df_wavg.loc[:,each] = df_allyrs_norm[df_allyrs_norm.period=='pre'].groupby(\"D_fha\").apply(wavg, each,weights_name).values\n",
    "\n",
    "print(df_wavg.transpose())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. DiD Model home values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Create dummies for different periods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def treatment_period(x):\n",
    "    if x <=1940: \n",
    "        return 'pre'\n",
    "    elif x<=1980: \n",
    "        return 'post'\n",
    "    else: \n",
    "        return 'reversal'\n",
    "\n",
    "    \n",
    "def get_dummies(df):\n",
    "\n",
    "    period_dummy = pd.get_dummies(df['period'].astype(str),prefix='period')\n",
    "    period_dummy = period_dummy[['period_pre','period_post','period_reversal']]\n",
    "\n",
    "    grade_dummy = pd.get_dummies(df['fha_grade'],prefix=None)\n",
    "    grade_dummy = pd.DataFrame(grade_dummy,index=df.index).rename(columns={'fha_grade':'grade_dummy'})\n",
    "\n",
    "    grade_dummy = df['fha_grade'].apply(lambda x: 1 if x=='D' else 0)\n",
    "    grade_dummy = pd.DataFrame(grade_dummy,index=df.index).rename(columns={'fha_grade':'D'})\n",
    "\n",
    "\n",
    "    neigh_dummy = pd.get_dummies(df['PRI_NEIGH'].astype(str),prefix=None)\n",
    "    neigh_dummy = pd.DataFrame(neigh_dummy).rename(columns={'PRI_NEIGH':'n_fe'})\n",
    "    neigh_dummy= neigh_dummy.iloc[:,1:]\n",
    "    \n",
    "    tract_dummy = pd.get_dummies(df['gisjoin'].astype(str),prefix=None)\n",
    "    tract_dummy = pd.DataFrame(tract_dummy).rename(columns={'gisjoin':'tract_fe'})\n",
    "    tract_dummy= tract_dummy.iloc[:,1:]\n",
    "\n",
    "\n",
    "    dummies_per = pd.concat([period_dummy, grade_dummy],axis=1)\n",
    "    \n",
    "    return df,period_dummy,grade_dummy,tract_dummy,neigh_dummy,dummies_per"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_interaction_dummies( period_dummy,dummies_per,grade_dummy):\n",
    "    string1 = \"\"    \n",
    "    \n",
    "    \n",
    "    for j in grade_dummy.columns: \n",
    "        for i in pd.concat([period_dummy],axis=1).columns: \n",
    "            string1= string1+ (\"{}:{}+\".format(i,j))\n",
    "    \n",
    "    per_grade_dummy = PatsyTransformer(string1[:-1], return_type=\"dataframe\").fit_transform(dummies_per) ## Clipping off the last bit of the '+'\n",
    "\n",
    "    return per_grade_dummy\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_feature_interaction_dummies( period_dummy1,features):\n",
    "    string1 = \"\"\n",
    "    \n",
    "    features_per = pd.concat([period_dummy1,features],axis=1)\n",
    "\n",
    "    \n",
    "    for j in features.columns: \n",
    "        for i in pd.concat([period_dummy1],axis=1).columns: \n",
    "            string1= string1+ (\"{}:{}+\".format(i,j))\n",
    "    \n",
    "    per_feature_dummy = PatsyTransformer(string1[:-1], return_type=\"dataframe\").fit_transform(features_per) ## Clipping off the last bit of the '+'\n",
    "\n",
    "    return per_feature_dummy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1 Create regression summary functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a function for running regressions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def run_reg(df,weights_col,features,outcome,g_dum,p_dum,p_g_dum,n_dum,model='WLS',std=False, lag_x=False,lag_y=False,neigh=False):\n",
    "    import datetime\n",
    "    now = datetime.date.today()\n",
    "    \n",
    "    X1 = df[features]\n",
    "    y1_1 = df[outcome]\n",
    "\n",
    "    ### Adjust for spatial autocorrelation\n",
    "    if lag_x==True: \n",
    "        X1_l = get_lags(df,features)\n",
    "    if lag_y==True: \n",
    "        y1_l = get_lags(df,[y])\n",
    "\n",
    "    ### Standardize optional\n",
    "    if std==True: \n",
    "        X1 = (X1-X1.mean())/X1.std()\n",
    "        y1_1 = (y1_1-y1_1.mean())/y1_1.std()\n",
    "        if lag_x==True:\n",
    "            X1_l = (X1_l-X1_l.mean())/X1_l.std()\n",
    "        if lag_y==True: \n",
    "            y1_l = (y1_l-y1_l.mean())/y1_l.std()\n",
    "    covariates = [X1,g_dum,p_dum,p_g_dum]\n",
    "    \n",
    "    if lag_x==True: \n",
    "        covariates.append(X1_l)\n",
    "    if lag_y==True: \n",
    "        covariates.append(y1_l)\n",
    "    if neigh==True: \n",
    "        covariates.append(n_dum)\n",
    "        \n",
    "        \n",
    "    X1_1= pd.concat(covariates,ignore_index=False,axis=1)\n",
    "    X1_1 = X1_1.fillna(value=X1_1.mean(axis=0))\n",
    "\n",
    "    weights = df[weights_col]\n",
    "    ####################\n",
    "    ##       OLS      ##\n",
    "    ####################\n",
    "    if model=='OLS':\n",
    "        mdl = sm.OLS(y1_1,X1_1,hasconst=True)\n",
    "        results = mdl.fit()\n",
    "\n",
    "\n",
    "        df['resid'] = results.resid\n",
    "        df['y'] = y1_1\n",
    "        df['y_pred'] = results.predict()\n",
    "\n",
    "        print(results.summary())\n",
    "        \n",
    "        \n",
    "    ####################\n",
    "    ##       WLS      ##\n",
    "    ####################\n",
    "    if model=='WLS':\n",
    "        mdl = sm.WLS(y1_1,X1_1,weights=weights,hasconst=False)\n",
    "        results = mdl.fit()\n",
    "\n",
    "\n",
    "        df['resid'] = results.resid\n",
    "        df['y'] = y1_1\n",
    "        df['y_pred'] = results.predict()\n",
    "\n",
    "        print(results.summary())\n",
    "\n",
    "\n",
    "    ####################\n",
    "    ## Applies to all ##\n",
    "    ####################\n",
    "\n",
    "    # Display the autocorrelation plot of your time series\n",
    "    from statsmodels.graphics import tsaplots\n",
    "\n",
    "    fig = tsaplots.plot_acf(df['resid'], lags=2)\n",
    "    plt.show()\n",
    "\n",
    "    for i in ['resid']:\n",
    "        print(i)\n",
    "        for y in df.period.unique():\n",
    "            W = ps.weights.Queen.from_dataframe(gpd.GeoDataFrame(df[df.period==y],\n",
    "                                                                           geometry='geometry',\n",
    "                                                                           crs={'init':'epsg:4326'}).to_crs(epsg=3857),\n",
    "                                               geom_col='geometry',\n",
    "                                               ids='gisjoin')\n",
    "            W.transform='r'\n",
    "            mi = Moran(df[df.period==y][i].values, W, two_tailed=True)\n",
    "            print(\"%.3f\"%mi.I,\"%.5f\"%mi.p_norm, \"%.3f\"%mi.EI)\n",
    "\n",
    "\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2 Function for Creating Spatial Lags"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_lags(df,features):\n",
    "    Xl_lst = []\n",
    "    for y in df.period.unique():\n",
    "        W = ps.weights.Queen.from_dataframe(gpd.GeoDataFrame(df[df.period==y],\n",
    "                                                                       geometry='geometry',\n",
    "                                                                       crs={'init':'epsg:4326'}).to_crs(epsg=3857),\n",
    "                                           geom_col='geometry',\n",
    "                                           ids='gisjoin')\n",
    "\n",
    "        W.transform='r'\n",
    "        Xl = ps.lag_spatial(W,df[df.period==y][features])\n",
    "        Xl_lst.append(Xl)\n",
    "    Xl_stack=np.vstack(tuple(Xl_lst))\n",
    "\n",
    "    X_lag = pd.DataFrame(Xl_stack,\n",
    "                 columns=['{}_l'.format(x) for x in features],\n",
    "                 index = df.index)\n",
    "    return X_lag"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_allyrs_norm_subgroup,period_dummy1,grade_dummy,tract_dummy,neigh_dummy,dummies_per = get_dummies(df_allyrs_norm)\n",
    "period_dummy =period_dummy1[['period_post','period_reversal']]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "per_grade_dummy = get_interaction_dummies(period_dummy,dummies_per,grade_dummy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.3 Model 1: Home Values\n",
    "- Just 1930 and 1940 values in the independent variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "weights_name = 'weights3'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mdl1_features= ['white_perc','white_perc_chng','black_perc','black_perc_chng',\n",
    "                'population_density','population_density_chng_perc',\n",
    "                'population','population_chng_perc',\n",
    "                'college_perc',\n",
    "                'owned_perc','owned_perc_chng','perc_college_10plus','perc_black_20plus','dist_downtown','e_w']\n",
    "\n",
    "# mdl1_features=[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_allyrs_mdl1_1 = pd.merge(df_allyrs_norm[['per_order','period','gisjoin']+['ln_median_homevalue_adj','fha_grade','D_fha',weights_name]],\n",
    "                                 df_final_psm[['gisjoin','geometry']+mdl1_features],\n",
    "                                 on=['gisjoin'],how='left')\n",
    "\n",
    "\n",
    "feat_dummies = get_feature_interaction_dummies(period_dummy1,df_allyrs_mdl1_1[mdl1_features])\n",
    "df_allyrs_mdl1_1 = pd.concat([df_allyrs_mdl1_1,feat_dummies],axis=1)\n",
    "mld1_1_results = run_reg(df_allyrs_mdl1_1,weights_name,feat_dummies.columns,'ln_median_homevalue_adj',\n",
    "                         grade_dummy,period_dummy,per_grade_dummy,neigh_dummy,\n",
    "                         model='WLS',std=True, lag_x=False,lag_y=False,neigh=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.4 Model 2: Home Ownership"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mdl2_features= ['white_perc','white_perc_chng','black_perc','black_perc_chng',\n",
    "                'population_density','population_density_chng_perc',\n",
    "                'population','population_chng_perc',\n",
    "                'college_perc',\n",
    "                'ln_median_homevalue_adj','ln_median_homevalue_adj_chng_perc',\n",
    "                'perc_college_10plus','perc_black_20plus','dist_downtown','e_w','e_w_chng_perc']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_allyrs_mdl2_1 = pd.merge(df_allyrs_norm[['per_order','period','gisjoin']+['owned_perc','fha_grade','D_fha',weights_name]],\n",
    "                                 df_final_psm[['gisjoin','geometry']+mdl2_features],\n",
    "                                 on=['gisjoin'],how='left')\n",
    "\n",
    "\n",
    "feat_dummies = get_feature_interaction_dummies(period_dummy1,df_allyrs_mdl2_1[mdl2_features])\n",
    "\n",
    "df_allyrs_mdl2_1 = pd.concat([df_allyrs_mdl2_1,feat_dummies],axis=1)\n",
    "\n",
    "mld2_1_results = run_reg(df_allyrs_mdl2_1,weights_name,feat_dummies.columns,'owned_perc',\n",
    "                         grade_dummy,period_dummy,per_grade_dummy,neigh_dummy,\n",
    "                         model='WLS',std=True, lag_x=False,lag_y=False,neigh=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5 Model 3: Segregation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mdl3_features= ['owned_perc','owned_perc_chng',\n",
    "                'population_density','population_density_chng_perc',\n",
    "                'population','population_chng_perc',\n",
    "                'college_perc',\n",
    "                'ln_median_homevalue_adj','ln_median_homevalue_adj_chng_perc','perc_college_10plus','dist_downtown']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model 3.1: Not year-standardized"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "df_allyrs_mdl3_1 = pd.merge(df_allyrs_norm_subgroup[['per_order','period','gisjoin']+['black_perc','e_w','fha_grade','D_fha',weights_name]],\n",
    "                                 df_final_psm[['gisjoin','geometry']+mdl3_features],\n",
    "                                 on=['gisjoin'],how='left')\n",
    "feat_dummies = get_feature_interaction_dummies(period_dummy1,df_allyrs_mdl3_1[mdl3_features])\n",
    "\n",
    "df_allyrs_mdl3_1 = pd.concat([df_allyrs_mdl3_1,feat_dummies],axis=1)\n",
    "\n",
    "mld3_1_results = run_reg(df_allyrs_mdl3_1,weights_name,feat_dummies.columns,'e_w',\n",
    "                         grade_dummy,period_dummy,per_grade_dummy,neigh_dummy,model='WLS',\n",
    "                         std=True, lag_x=False,lag_y=False,neigh=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "29aca0769ada4e9296ff49aad6a3de7904edbb97f6b91a72130e5b5d8e147b29"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}