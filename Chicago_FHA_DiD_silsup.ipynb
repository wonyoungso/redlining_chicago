{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook Goals\n",
    "The goal of this notebook is to replicate the result of HOLC Chicago. Perhaps do the expansion job on the other python notebooks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context('paper')\n",
    "\n",
    "paper_cmap = {\"A\":\"#5FCE72\",\"B\":\"#0BC0ED\",\"C\":\"#FFD419\",\"D\":\"#FF4B19\"}\n",
    "paper_colors = LinearSegmentedColormap('paper_colors', paper_cmap)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import glob\n",
    "import requests\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely import wkt\n",
    "\n",
    "import psycopg2  # (if it is postgres/postgis)\n",
    "conn = psycopg2.connect(database=\"chicago_fha\", user=\"wonyoungso\", password=\"\",\n",
    "    host=\"localhost\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://wonyoungso:@localhost:5432/chicago_fha')\n",
    "\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from patsylearn import PatsyModel, PatsyTransformer\n",
    "\n",
    "import libpysal as ps\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as st\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df_final = gpd.read_file('data/chicago_census_historical/chicago_census_historical.shp')\n",
    "\n",
    "df_final = df_final.rename(columns={'asian': 'asian',\n",
    " 'asian_pe_1': 'asian_perc_norm',\n",
    " 'asian_perc': 'asian_perc',\n",
    " 'black': 'black',\n",
    " 'black_norm': 'black_norm',\n",
    " 'black_pe_1': 'black_perc_norm',\n",
    " 'black_perc': 'black_perc',\n",
    " 'college': 'college',\n",
    " 'college__1': 'college_perc_norm',\n",
    " 'college_pe': 'college_perc',\n",
    " 'gisjoin': 'gisjoin',\n",
    " 'gisjoin_19': 'gisjoin_1940',\n",
    " 'hispanic': 'hispanic',\n",
    " 'hispanic_1': 'hispanic_perc_norm',\n",
    " 'hispanic_p': 'hispanic_perc',\n",
    " 'holc_grade': 'holc_grade',\n",
    " 'homes': 'homes',\n",
    " 'ln_homeval': 'ln_homeval_norm',\n",
    " 'ln_income_': 'ln_income_norm',\n",
    " 'ln_media_1': 'ln_median_homevalue_adj',\n",
    " 'ln_median_': 'ln_median_income',\n",
    " 'map_id': 'map_id',\n",
    " 'median_h_1': 'median_homevalue_adj',\n",
    " 'median_hom': 'median_homevalue',\n",
    " 'median_i_1': 'median_income',\n",
    " 'median_inc': 'median_income_adj',\n",
    " 'other': 'other',\n",
    " 'other_perc': 'other_perc',\n",
    " 'owned_pe_1': 'owned_perc_norm',\n",
    " 'owned_perc': 'owned_perc',\n",
    " 'populati_1': 'population_density',\n",
    " 'populati_2': 'population_density_norm',\n",
    " 'populati_3': 'population_norm',\n",
    " 'population': 'population',\n",
    " 'unemploy_1': 'unemployed_perc',\n",
    " 'unemploy_2': 'unemployed_perc_norm',\n",
    " 'unemployed': 'unemployed',\n",
    " 'white': 'white',\n",
    " 'white_norm': 'white_norm',\n",
    " 'white_pe_1': 'white_perc_norm',\n",
    " 'white_perc': 'white_perc',\n",
    " 'year': 'year'})\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_final['nonblack_perc'] = 1 - df_final['black_perc']/df_final['population']\n",
    "df_final['perc_college_10plus'] = [1 if x > 0.10 else 0 for x in df_final['college_perc']]\n",
    "\n",
    "# Need to create some extra features for the propensity scoring to increase similarity between 'before' tracts. \n",
    "df_final['perc_black_20plus'] = [1 if x > 0.20  else 0 for x in df_final['black_perc']]\n",
    "df_final['perc_college_10plus'] = [1 if x > 0.10  else 0 for x in df_final['college_perc']]\n",
    "\n",
    "# Create a point that represents roughly downtown is \n",
    "downtown = Point(-87.62, 41.855)\n",
    "df_final['dist_downtown'] = df_final.distance(Point(-87.62,41.855))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create different treatment periods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# there is no 1950?\n",
    "print(df_final.shape)\n",
    "print(df_final[df_final.year != 1950].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6289, 48)\n",
      "(6289, 48)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_final1 = df_final[df_final.year != 1950]\n",
    "df_final1.loc[df_final1.year <= 1940,'period']='pre'\n",
    "df_final1.loc[(df_final1.year > 1940) & (df_final1.year <= 1980), 'period']='post'\n",
    "\n",
    "df_final1.loc[(df_final1.year>1980),'period']='reversal'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df_final1['fha_grade'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "D    2541\n",
       "C    1975\n",
       "B    1117\n",
       "A     656\n",
       "Name: fha_grade, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Create the D vs non-D FHA labels\n",
    "df_final1['D_fha'] = df_final1.apply(lambda x: 'D' if x['fha_grade']=='D' else 'not_D_fha', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def decade_scaler(x):\n",
    "  scaler = MinMaxScaler()\n",
    "  return scaler.fit_transform(x)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "29aca0769ada4e9296ff49aad6a3de7904edbb97f6b91a72130e5b5d8e147b29"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}